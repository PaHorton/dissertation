\chapter{ASTHROS Raspberry Pi Compute Module 4 Setup Guide}
\label{readout/app:cm4_setup}
From a fresh install of Raspberry Pi OS, we need to install the necessary packages to run the readout system.
The first step is to enable Secure Shell (SSH) so that we can remotely access the Raspberry Pi.
This can be done in the Raspberry Pi Configuration tool by enabling SSH in the Interfaces tab.
While we are in the interfaces tool, we must enable SPI and Remote GPIO. 
These are necessary to interface with the PMCC.

Next, we need to configure the networking interfaces. 
\texttt{eth0} is the wired interface to the rest of the readout network. 
We need a static IP for the CM4 to ensure that other devices on the network can easily find it.
In the network settings at the top right of the screen, we can select "Edit Connections" under Advanced Options. 
From there is "Wired connection 1" which is the default name for the wired interface.
Select the interface and navigate to the IPv4 Settings tab.
Change the method from "Automatic (DHCP)" to "Manual" and add the IP address, Netmask, and Gateway.
For ASTHROS, we have the IP addresses of all CM4s set to \texttt{192.168.1.13X} where \texttt{X} is uniquely assigned to each CM4.
The Netmask is set to \texttt{23} so we can access all devices on the \texttt{192.168.1.X} readout network as well as the \texttt{192.168.0.X} gondola network.
Finally, the Gateway is set to \texttt{192.168.1.1} when attached to the gondola and \texttt{192.168.1.101} when attached to the readout network.
This is because, when connected to a test bench, we utilize the NAS as our router to access other devices on the network.
When connected in flight configuration, we disable the NAS's router functionality and use the gondola's router instead.

Next, we need to configure the SPI interface to work with the PMCCs.
This process is different for Compute Module 5s (CM5s) as they have a different SPI driver and interfaces for the GPIO pins.
ASTHROS is currently in the process of upgrading to CM5s, but this documentation is focused on the setup for Compute Module 4s (CM4s).
The first step is to increase the SPI buffer size.
This is done by appending the following to the end of the \texttt{/boot/cmdline.txt} file:
\begin{verbatim}
    spidev.bufsiz=65536
\end{verbatim}
This sets the SPI buffer size to 64KB which is the maximum size to support the burst readout of the PMCCs.
For loading on boot, we need to add the SPI device to the \texttt{/etc/modules} file.
This is done by adding the following line to the file:
\begin{verbatim}
    spi_bcm2835
\end{verbatim}
Each of the CM4s will control up to four PMCCs, so we need to enable unique SPI busses for each PMCC.
This is done on the \texttt{/boot/config.txt} file by adding the following lines:
\begin{verbatim}
    dtoverlay=spi0-1cs
    dtoverlay=spi3-1cs
    dtoverlay=spi4-1cs
    dtoverlay=spi5-1cs
\end{verbatim}
This enables the SPI0, SPI3, SPI4, and SPI5 busses on the CM4.
While we could, in theory, only use two SPI busses and use the chip select lines to control two PMCCs on each bus, we decided to use a single chip select line for each PMCC to simplify the wiring harness and ensure our bandwidth is not saturated.

At this point, it is a good idea to reboot the CM4 to ensure that all changes have taken effect.
To verify the SPI busses are enabled, we check the \texttt{/dev} directory for the SPI devices which should be \texttt{/dev/spidevX.0} where \texttt{X} is the SPI bus number (0, 3, 4, or 5).
After rebooting and verifying the SPI has been set up, we recommend connecting the CM4 to the internet through a wireless hotspot in order to install the necessary libraries.
The first library we need to install is the \texttt{pigpio}.
This is a library that allows us to control the GPIO pins on the CM4 without needing root access.
To install the \texttt{pigpio} library, we need to run the following commands:
\begin{verbatim}
    sudo apt-get update
    sudo apt-get install pigpio
\end{verbatim}
After installing the \texttt{pigpio} library, we need to enable the \texttt{pigpio} daemon to run on boot.
This is done by running the following command:
\begin{verbatim}
    sudo systemctl enable pigpiod
\end{verbatim}

Finally, we need to install the custom Python packages that we will use to control the PMCC.
First we need to clone the \texttt{PyMCC} repository from GitHub.
This is done by running the following command:
\begin{verbatim}
    git clone https://github.com/asthros/pymcc.git
\end{verbatim}
Because this is a private repository, you will need to enter your GitHub username and personal access token.
You will need to generate a personal access token on GitHub and use that as your password when prompted.
After cloning the repository, we need to install the Python packages.
This is done by running the following command:
\begin{verbatim}
    pip3 install -r pymcc/requirements.txt
\end{verbatim}
This will install all the necessary packages to run the \texttt{PyMCC} package.

Finally, we need to edit the hosts file on the CM4 to ensure that we can access the other devices on the readout network by name.
This is done by updating the \texttt{/etc/hosts} file with following the IP addresses and hostnames:
\begin{verbatim}
    192.168.1.102  Main Switch
    192.168.1.103  Sub Switch
    192.168.1.110  commander
    192.168.1.111  storage
    192.168.1.112  analysis
    192.168.1.120  spectra1A
    192.168.1.121  spectra1B
    192.168.1.122  spectra2A
    192.168.1.123  spectra2B
    192.168.1.130  varattio1
    192.168.1.131  varattio2
    192.168.1.132  varattio3
\end{verbatim}

\chapter{Amplifier Chain Error Handling}
\label{readout/app:if_amp_errors}
Error codes for the amplifier chain are hard coded into the firmware of the Arduino.
Our driver code returns the following status codes whenever an error occurs in performing any read or write operation to the amplifier chain.
The hundreds digit of the error code indicates at what point in the control loop the error occurred.
In the case of a read, this value is 0 as there is only one operation performed.
In the case of a write, the value is 0 if an error occurred during the write operation and 1 if an error occurred during the subsequent read operation.

Our first response is what occurs during nominal operation:
\begin{itemize}
    \item \texttt{X00} - No error
\end{itemize}
From here on, the errors are sorted by the system that is reporting the error.
Errors with data validation:
\begin{itemize}
    \item \texttt{X01} - Bad Address Received
    \item \texttt{X02} - Bad Attenuation Received
\end{itemize}
Errors with connecting to the LCT4302:
\begin{itemize}
    \item \texttt{X11} - Buffer Overflow from LCT4302 Connection
    \item \texttt{X12} - NACK Received from LCT4302 connection
    \item \texttt{X13} - Bus Error or Arbitration Lost from LCT4302 connection
    \item \texttt{X14} - Timeout from LCT4302 connection
    \item \texttt{X15} - Unknown Error from LCT4302 connection
\end{itemize}
Errors connecting to the PCA9571:
\begin{itemize}
    \item \texttt{X21} - Buffer Overflow from PCA9571 Connection
    \item \texttt{X22} - NACK Received from PCA9571 connection
    \item \texttt{X23} - Bus Error or Arbitration Lost from PCA9571 connection
    \item \texttt{X24} - Timeout from PCA9571 connection
    \item \texttt{X25} - Unknown Error from PCA9571 connection
\end{itemize}
Errors disconnecting from the LCT4302:
\begin{itemize}
    \item \texttt{X31} - Buffer Overflow from LCT4302 Disconnection
    \item \texttt{X32} - NACK Received from LCT4302 disconnection
    \item \texttt{X33} - Bus Error or Arbitration Lost from LCT4302 disconnection
    \item \texttt{X34} - Timeout from LCT4302 disconnection
    \item \texttt{X35} - Unknown Error from LCT4302 disconnection
\end{itemize}

\chapter{Previously Published Work}
\section{Integrating Novelty Detection Capabilities with MSL Mastcam Operations to Enhance Data Analysis}
The content of Chapter \ref{ch:msl} was previously published in 2021 as part of the Proceedings of the 2021 IEEE Aerospace Conference.
The content of the chapter has been modified to include additional work and minor formatting changes were made to comply with the ASU dissertation formatting guide.
Co-authors have granted permission for the inclusion of this publication in this dissertation. 
Below is the full citation and original abstract.
\begin{refsection}
  \nocite{horton2021integrating}
  \printbibliography[heading=none]
\end{refsection}
\subsection{Abstract}
While innovations in scientific instrumentation have pushed the boundaries of Mars rover mission capabilities, the increase in data complexity has pressured Mars Science Laboratory (MSL) and future Mars rover operations staff to quickly analyze complex data sets to meet progressively shorter tactical and strategic planning timelines. MSLWEB is an internal data tracking tool used by operations staff to perform first pass analysis on MSL image sequences, a series of products taken by the Mast camera, Mastcam. Mastcam consists of a pair of 400-1000 nm wavelength cameras on MSL's Remote Sensing Mast that, among other functions, uses a filter wheel to produce multispectral images by creating a sequence of products at different wavelengths. Mastcam's multiband multispectral image sequences require more complex analysis compared to standard 3-band RGB images. Typically, these are analyzed by the inspection of false color images created to aid visualization, such as band ratios between different spectral indices that can highlight specific potential mineralogic differences among iron-bearing phases, and decorrelation stretches to enhance the color differences between multiple filters. Given the short time frame of tactical planning in which down-linked images might need to be analyzed (within 5-10 hours before the next uplink), there exists a need to triage analysis time to focus on the most important sequences and parts of a sequence. We address this need by creating products for MSLWEB that use novelty detection to help operations staff identify unusual data that might be diagnostic of new or atypical compositions or mineralogies detected within an imaging scene. This was achieved in two ways: 1) by creating products for each sequence to identify novel regions in the image, and 2) by assigning multispectral sequences a sortable novelty score. These new products provide colorized heat maps of inferred novelty that operations staff can use to rapidly review down-linked data and focus their efforts on analyzing potentially new kinds of diagnostic multispectral signatures. This approach has the potential to guide scientists to new discoveries by quickly drawing their attention to often subtle variations not detectable with simple color composites. The products developed in this work have shown promising benefits for integration into mission operations by potentially decreasing tactical operations planning time through guided triage.

\section{Anomaly Detection for the Roman Space Telescope Wide Field Instrument’s Science Data Processing Pipeline}
The content of Chapter \ref{ch:rst} was previously published in 2023 as part of the Proceedings of the 2023 SPIE Astronomical Telescopes + Instrumentation Conference.
The content of the chapter has been modified to include additional work and minor formatting changes were made to comply with the ASU dissertation formatting guide.
Co-authors have granted permission for the inclusion of this publication in this dissertation. 
Below is the full citation and original abstract.
\begin{refsection}
  \nocite{horton2024anomaly}
  \printbibliography[heading=none]
\end{refsection}
\subsection{Abstract}
The Roman Space Telescope (RST) Wide Field Instrument (WFI) will be utilizing a preliminary Science Data Processing (SDP) pipeline during its Integration and Test, and to some extent during Operations, to track basic statistics and identify known features such as cosmic rays, snowballs as well as possible anomalies in raw detector data. In our detectors, these anomalies appear as jumps in the ramp of a readout and are classified as cosmic rays if they appear as a streak or snowballs if they’re more circular. The WFI employs an array of 18 H4RG-10 detectors that collect image samples. Each set of raw frames within a non-destructive exposure is packaged by the SDP pipeline into image cubes for each detector. Each cube is a time series of 4096 × 4096 accumulating pixel frames. The preliminary analysis pipeline is used to locate anomalies in these time-series accumulation frames and identify the type of anomaly, either natural phenomena or detector characteristic. To compare different methods, we’ve implemented both heuristic-based and data-driven methods to identify anomalies. For the heuristic-based approach, we identify snowballs and cosmic rays by the size and shape of outlier pixel clusters between consecutive frames. For data driven methods, we evaluated a Convolutional Neural Network (CNN) model, and more traditional methods like Principal Component Analysis (PCA). CNN is a supervised learning/classification method. Thus, we used a labeled dataset of anomalies to perform segmentation of the image and identify anomalies. We used previously identified cosmic rays and snowballs to measure the accuracy and efficiency of the mentioned approaches. In evaluating these methods, we aim to pick the best fit for the SDP pipeline’s anomaly detection in terms of both performance and runtime.

\section{On-board Science Data Quality Analysis using Anomaly Detection for ASTHROS}
The content of Chapter \ref{ch:spectra} was previously published in 2023 as part of the Proceedings of the 2023 SPIE Astronomical Telescopes + Instrumentation Conference.
The content of the chapter has been modified to include additional work and minor formatting changes were made to comply with the ASU dissertation formatting guide.
Co-authors have granted permission for the inclusion of this publication in this dissertation. 
Below is the full citation and original abstract.
\begin{refsection}
  \nocite{horton2024board}
  \printbibliography[heading=none]
\end{refsection}
\subsection{Abstract}
ASTHROS (Astrophysics Stratospheric Telescope for High Spectral Resolution Observations at Submillimeter-wavelengths) is a high-altitude balloon mission utilizing an array of sixteen spectrometers to create high spatial resolution 3D maps of ionized nitrogen gas in galactic and extragalactic star-forming regions. During data collection, we utilize on-the-fly mapping, where the instrument continuously collects spectra while scanning over a target area. After a sweep across the target, we take a calibration spectra to correct our science data. These calibration spectra provide a baseline for how the instrument is operating at a given moment. As we collect new calibration spectra, we can compare the current calibration with a series of past calibrations to determine if our system is producing anomalous spectra. Some examples of anomalous spectra are changes in RFI spike frequency, location, or amplitudes, changes in the overall readout level, and changes in the shape of the spectra. We compare statistical and data-driven methods for detecting these anomalies and evaluate their performance to determine the best fit for the ASTHROS readout system. For data-driven methods, we compare the latent space representation of our calibration spectra with past calibrations using models like Variational AutoEncoders (VAE) and Principal Component Analysis (PCA). By comparing with a rolling window of past calibrations, we allow our system to change gradually while identifying sudden irregularities. When spectra are labeled as anomalous, they are prioritized for review so that the ground operations team can analyze and address the issue. On-board analysis is enabled by the readout system architecture which utilizes the RabbitMQ (RMQ) messaging networking. RMQ allows us to modularly build our readout system and create additional functionality, such as on-board analysis, without making modifications to the operation pipeline.
